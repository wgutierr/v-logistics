{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "40bdfa2a-2381-4daa-81f9-82cbacb597db",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Funciones basicas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Funciones de graficación\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Funciones de pronóstico y estadisticas\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.stattools import acf\n",
    "import math\n",
    "from math import sqrt\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Funciones de manejo de fechas\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Funciones de manejo de texto\n",
    "import re\n",
    "\n",
    "# Funciones de manejo de archivos\n",
    "import os\n",
    "import io\n",
    "\n",
    "# Funciones de manejo de excepciones\n",
    "import sys\n",
    "# Funciones para la interfaz de usuario\n",
    "try:\n",
    "    import streamlit as st\n",
    "    USANDO_STREAMLIT = 'streamlit' in sys.modules\n",
    "except ImportError:\n",
    "    st = None\n",
    "    USANDO_STREAMLIT = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d335b9b",
   "metadata": {},
   "source": [
    "# Funciones de Apoyo de Carga de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88182a32-b6cb-4765-b1ab-a93310d3a293",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Carga de datos de demanda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4be9277c-3ab0-4856-9aa4-6d13d495b0c1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cargar_demandas(ruta_demandas):\n",
    "\n",
    "    # Lista para almacenar cada DataFrame\n",
    "    dataframes = []\n",
    "\n",
    "    # Itera sobre cada archivo en la carpeta\n",
    "    for filename in os.listdir(ruta_demandas):\n",
    "        if filename.endswith('2025.csv'):\n",
    "            # Extrae \"Producto\" y \"Regional\" del nombre del archivo\n",
    "            regional, año = filename.split('_')\n",
    "            año = año.replace('.csv', '')\n",
    "            \n",
    "            # Carga el archivo y añade las columnas \"Producto\" y \"Regional\"\n",
    "            df = pd.read_csv(os.path.join(ruta_demandas, filename))\n",
    "            df['REGIONAL'] = regional\n",
    "            print(f'Ultimo turno {regional}:',df['Turn'].max())\n",
    "            # Agrega el DataFrame a la lista\n",
    "            dataframes.append(df)\n",
    "\n",
    "    # Concatena todos los DataFrames en uno solo\n",
    "    df_agregado = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    return df_agregado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "07f524da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_demandas_por_region(archivo_norte, archivo_centro, archivo_sur):\n",
    "    \n",
    "    \"\"\"\n",
    "    Carga y concatena los archivos de demanda por región (NORTE, CENTRO, SUR) \n",
    "    desde archivos subidos vía Streamlit.\n",
    "    \"\"\"\n",
    "\n",
    "    dataframes = []\n",
    "\n",
    "    archivos = {\n",
    "        'NORTE': archivo_norte,\n",
    "        'CENTRO': archivo_centro,\n",
    "        'SUR': archivo_sur\n",
    "    }\n",
    "\n",
    "    for region, archivo in archivos.items():\n",
    "        if archivo is not None:\n",
    "            df = pd.read_csv(archivo)\n",
    "            df['REGIONAL'] = region\n",
    "            st.write(f\"✅ Último turno cargado para {region}: {df['Turn'].max()}\")\n",
    "            dataframes.append(df)\n",
    "\n",
    "    df_agregado = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    return df_agregado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b28519",
   "metadata": {},
   "source": [
    "## Carga de datos maestros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d76d3980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_data_maestra(ruta_data_maestra):\n",
    "\n",
    "    # Carga todas las hojas como diccionario\n",
    "    hojas = pd.read_excel(ruta_data_maestra, sheet_name=None)  \n",
    "\n",
    "    # Crear un DataFrame por cada hoja con nombre df_{nombre_hoja}\n",
    "    for nombre_hoja, df in hojas.items():\n",
    "        # Limpiar y estandarizar el nombre de la hoja\n",
    "        nombre_limpio = re.sub(r'\\W+', '_', nombre_hoja.lower())  # Minúsculas y reemplazo de no alfanuméricos por \"_\"\n",
    "        globals()[f\"df_{nombre_limpio}\"] = df\n",
    "\n",
    "    # (Opcional) Verificar los nombres creados\n",
    "    print(\"Hojas cargadas:\", [f\"df_{re.sub(r'\\\\W+', '_', nombre.lower())}\" for nombre in hojas.keys()])\n",
    "    \n",
    "    return df_bom_mp, df_m_d_o, df_transporte, df_almacenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee998f2",
   "metadata": {},
   "source": [
    "# Funciones de Apoyo para Preprocesamiento de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bce7b9",
   "metadata": {},
   "source": [
    "### Producto terminado Parte 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "02e1f084",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocesar_datos_parte_1(df_agregado, productos):\n",
    "\n",
    "    \"\"\"\n",
    "    Toma las demandas agregadas y la lista de productos,\n",
    "    limpia los nombres de columnas, estandariza los nombres de las regionales,\n",
    "    genera dos agregados adicionales:\n",
    "    - 'CEDI': suma de CENTRO + SUR\n",
    "    - 'MOTOTRAK': suma de NORTE + CENTRO + SUR\n",
    "    Concatena estos agregados al DataFrame original y lo ordena.\n",
    "    Devuelve el DataFrame final listo para análisis o modelado.\n",
    "    \"\"\"\n",
    "\n",
    "    # Limpiar nombres de columnas\n",
    "    df_agregado.columns = df_agregado.columns.str.replace(r\"\\s*\\(Product\\)\", \"\", regex=True).str.strip()\n",
    "    df_agregado['REGIONAL'] = df_agregado['REGIONAL'].str.upper()\n",
    "\n",
    "    # Crear CEDI: CENTRO + SUR\n",
    "    df_cedi = df_agregado[df_agregado['REGIONAL'].isin(['CENTRO', 'SUR'])].groupby('Turn')[productos].sum().reset_index()\n",
    "    df_cedi['REGIONAL'] = 'CEDI'\n",
    "\n",
    "    # Crear MOTOTRAK: NORTE + CENTRO + SUR\n",
    "    df_mototrak = df_agregado[df_agregado['REGIONAL'].isin(['NORTE', 'CENTRO', 'SUR'])].groupby('Turn')[productos].sum().reset_index()\n",
    "    df_mototrak['REGIONAL'] = 'MOTOTRAK'\n",
    "\n",
    "    # Concatenar todo\n",
    "    df_final = pd.concat([df_agregado, df_cedi, df_mototrak], ignore_index=True)\n",
    "\n",
    "    # Mostar df\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832d8654",
   "metadata": {},
   "source": [
    "### Producto terminado Parte 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d07c77ef-c6fc-4e10-95a2-74a2c0bbf673",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocesar_datos_parte_2(df_final):\n",
    "    \n",
    "    \"\"\"    Transforma el DataFrame df_final para que las columnas de productos\n",
    "    ('MOTO', 'CUATRIMOTO', 'TRACTOR') se conviertan en filas,\n",
    "    manteniendo 'Turn' y 'REGIONAL' como columnas fijas.\n",
    "    \"\"\"\n",
    "\n",
    "    # Transformar el DataFrame utilizando pd.melt\n",
    "    df = pd.melt(\n",
    "        df_final, \n",
    "        id_vars=['Turn', 'REGIONAL'],  # Columnas que permanecen fijas\n",
    "        value_vars=['MOTO', 'CUATRIMOTO', 'TRACTOR'],  # Columnas que se convertirán en filas\n",
    "        var_name='PRODUCTO',  # Nombre para la nueva columna de productos\n",
    "        value_name='DEMANDA'  # Nombre para la nueva columna de valores\n",
    "    )\n",
    "\n",
    "    # Eliminar filas con DEMANDA nula (Tractor en Sur)\n",
    "    df = df.dropna(subset='DEMANDA').reset_index(drop=True)\n",
    "\n",
    "    # Visualizar el resultado\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce8411c",
   "metadata": {},
   "source": [
    "### Materia Prima Preprocesamiento BOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a74b441e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocesar_datos_mp(df_bom_mp):\n",
    "    \"\"\"\n",
    "    Transforma el DataFrame df_bom_mp para que la columna de producto\n",
    "    se conviertan en filas,\n",
    "    manteniendo 'MATERIA_PRIMA' como columna fija.\n",
    "    \"\"\"\n",
    "    # Seleccionar las columnas relevantes y renombrar 'PRODUCTO' a 'MATERIA_PRIMA'\n",
    "    df_bom = df_bom_mp.rename(columns={'PRODUCTO':'MATERIA_PRIMA'}).iloc[:,:4]\n",
    "\n",
    "    # Transformar el DataFrame utilizando pd.melt\n",
    "    df_bom_vertical = df_bom.melt(id_vars=['MATERIA_PRIMA'], \n",
    "                                    var_name='PRODUCTO', \n",
    "                                    value_name='CANTIDAD')\n",
    "    \n",
    "    # Eliminar filas con CANTIDAD nula o cero\n",
    "    df_bom_vertical = df_bom_vertical[df_bom_vertical['CANTIDAD'] != 0]\n",
    "    \n",
    "    return df_bom_vertical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b551834",
   "metadata": {},
   "source": [
    "### Materia Prima - Explosión de Materiales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c392cc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explosionar_mp(df, df_bom_vertical):\n",
    "\n",
    "    \"\"\"\n",
    "    Explosiona el DataFrame df_mototrak con los datos de la BOM vertical\n",
    "    para calcular el consumo de cada material por Turno.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filtrar df_mototrak\n",
    "    df_mototrak = df[df['REGIONAL'] == 'MOTOTRAK'].copy()\n",
    "\n",
    "    # Paso 1: Unir df_mototrak con df_bom_vertical por 'PRODUCTO'\n",
    "    df_explosion = df_mototrak.merge(df_bom_vertical, on='PRODUCTO', how='left')\n",
    "\n",
    "    # Paso 2: Calcular el consumo de cada material por Turn\n",
    "    df_explosion['CONSUMO'] = df_explosion['DEMANDA'] * df_explosion['CANTIDAD']\n",
    "\n",
    "    # Paso 3: Agrupar por Turno y Materia Prima\n",
    "    df_consumo = (\n",
    "        df_explosion\n",
    "        .groupby(['Turn', 'MATERIA_PRIMA'], as_index=False)\n",
    "        .agg({'CONSUMO': 'sum'})\n",
    "        .rename(columns={'CONSUMO': 'DEMANDA_MATERIA_PRIMA'})\n",
    "    )\n",
    "\n",
    "    # Mostrar el DataFrame resultante\n",
    "    return df_consumo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f237a805-d0ae-43d6-8887-e67e995b3cba",
   "metadata": {},
   "source": [
    "# Funciones de Ayuda para Gráficas de Demanda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befa195d",
   "metadata": {},
   "source": [
    "## Función para graficar la demanda del producto terminado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cfbfb628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficar_demanda_pt(df, colores_pt):\n",
    "\n",
    "    \"\"\"\n",
    "    Crea un gráfico de líneas para la demanda de productos terminados\n",
    "    por regionales y productos, utilizando Plotly.\n",
    "    \"\"\"\n",
    "\n",
    "    # Listas de regionales y productos únicos\n",
    "    regionales = df['REGIONAL'].unique().tolist()\n",
    "    productos = df['PRODUCTO'].unique().tolist()\n",
    "\n",
    "    # Crear figura 2x3\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=3, \n",
    "        subplot_titles=[\"NORTE\", \"CENTRO\", \"SUR\", \"CEDI (C+S)\", \"MOTOTRAK (N+C+S)\", \"\"]\n",
    "    )\n",
    "\n",
    "    # Mapeo a subplot\n",
    "    subplot_pos = {\n",
    "        'NORTE': (1, 1),\n",
    "        'CENTRO': (1, 2),\n",
    "        'SUR': (1, 3),\n",
    "        'CEDI': (2, 1),\n",
    "        'MOTOTRAK': (2, 2)\n",
    "    }\n",
    "\n",
    "    # Mostrar leyenda solo en el primer subplot\n",
    "    showlegend_flag = True\n",
    "\n",
    "    # Trazar por cada regional\n",
    "    for region in regionales:\n",
    "        row, col = subplot_pos[region]\n",
    "        df_region = df[df['REGIONAL'] == region]\n",
    "        for producto in productos:\n",
    "            df_sub = df_region[df_region['PRODUCTO'] == producto]\n",
    "            if not df_sub.empty:\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=df_sub['Turn'], \n",
    "                        y=df_sub['DEMANDA'], \n",
    "                        mode='lines',\n",
    "                        name=producto,\n",
    "                        line=dict(color=colores_pt[producto]),\n",
    "                        showlegend=showlegend_flag\n",
    "                    ),\n",
    "                    row=row, col=col\n",
    "                )\n",
    "        showlegend_flag = False  # Solo en el primer gráfico\n",
    "\n",
    "    # Layout\n",
    "    fig.update_layout(\n",
    "        height=700, width=1200,\n",
    "        title_text=\"Demanda por Regional y Agregados\",\n",
    "        showlegend=True,\n",
    "        legend_title=\"Producto\",\n",
    "        template=\"ggplot2\"\n",
    "    )\n",
    "\n",
    "    # Etiquetas comunes\n",
    "    fig.update_xaxes(title_text=\"Turn\", row=2, col=1)\n",
    "    fig.update_xaxes(title_text=\"Turn\", row=2, col=2)\n",
    "    fig.update_yaxes(title_text=\"Demanda\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Demanda\", row=2, col=1)\n",
    "\n",
    "    # Mostrar gráfico\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d76f14",
   "metadata": {},
   "source": [
    "## Función para graficar los pronósticos de productos terminados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b83be08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficar_pronosticos_pt(df, resultados_pt, colores_pt):\n",
    "\n",
    "    # Listas de regionales y productos únicos\n",
    "    regionales = df['REGIONAL'].unique().tolist()\n",
    "    productos = df['PRODUCTO'].unique().tolist()\n",
    "\n",
    "    # Crear figura 2x3\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=3,\n",
    "        subplot_titles=[\"NORTE\", \"CENTRO\", \"SUR\", \"CEDI (C+S)\", \"MOTOTRAK (N+C+S)\", \"\"]\n",
    "    )\n",
    "\n",
    "    # Posiciones de subplots\n",
    "    subplot_pos = {\n",
    "        'NORTE': (1, 1),\n",
    "        'CENTRO': (1, 2),\n",
    "        'SUR': (1, 3),\n",
    "        'CEDI': (2, 1),\n",
    "        'MOTOTRAK': (2, 2)\n",
    "    }\n",
    "\n",
    "    # Mostrar leyenda solo una vez\n",
    "    showlegend_flag = True\n",
    "\n",
    "    # Agregar trazos de demanda real y pronóstico\n",
    "    for region in regionales:\n",
    "        row, col = subplot_pos[region]\n",
    "        df_region = df[df['REGIONAL'] == region]\n",
    "\n",
    "        for producto in productos:\n",
    "            # 1. Demanda real\n",
    "            df_sub = df_region[df_region['PRODUCTO'] == producto]\n",
    "            clave = (region, producto)\n",
    "\n",
    "            if not df_sub.empty:\n",
    "                # Si hay pronóstico, ajustar la longitud del histórico\n",
    "                if clave in resultados_pt:\n",
    "                    pronostico_final = resultados_pt[clave][\"pronostico_final\"]\n",
    "                    mejor_modelo = resultados_pt[clave][\"mejor_modelo\"]\n",
    "\n",
    "                    lags = len(pronostico_final)  # Cantidad de pasos de pronóstico\n",
    "                    df_sub = df_sub.tail(52 + lags)  # Cortar a los últimos 52 + lags\n",
    "\n",
    "                    fig.add_trace(\n",
    "                        go.Scatter(\n",
    "                            x=df_sub['Turn'],\n",
    "                            y=df_sub['DEMANDA'],\n",
    "                            mode='lines',\n",
    "                            name=producto,\n",
    "                            line=dict(color=colores_pt[producto]),\n",
    "                            showlegend=showlegend_flag\n",
    "                        ),\n",
    "                        row=row, col=col\n",
    "                    )\n",
    "\n",
    "                    if not pronostico_final.empty:\n",
    "                        fig.add_trace(\n",
    "                            go.Scatter(\n",
    "                                x=pronostico_final.index,\n",
    "                                y=pronostico_final[mejor_modelo],\n",
    "                                mode='lines',\n",
    "                                name=f\"{producto} ({mejor_modelo})\",\n",
    "                                line=dict(dash='dot', color=colores_pt[producto]),\n",
    "                                showlegend=showlegend_flag\n",
    "                            ),\n",
    "                            row=row, col=col\n",
    "                        )\n",
    "                else:\n",
    "                    # Si no hay pronóstico, igual limitar a últimos 52 datos\n",
    "                    df_sub = df_sub.tail(52)\n",
    "                    fig.add_trace(\n",
    "                        go.Scatter(\n",
    "                            x=df_sub['Turn'],\n",
    "                            y=df_sub['DEMANDA'],\n",
    "                            mode='lines',\n",
    "                            name=producto,\n",
    "                            line=dict(color=colores_pt[producto]),\n",
    "                            showlegend=showlegend_flag\n",
    "                        ),\n",
    "                        row=row, col=col\n",
    "                    )\n",
    "\n",
    "        showlegend_flag = False  # Solo mostrar en el primer subplot\n",
    "\n",
    "    # Layout final\n",
    "    fig.update_layout(\n",
    "        height=700, width=1200,\n",
    "        title_text=\"Demanda Real y Pronóstico por Regional y Producto\",\n",
    "        showlegend=True,\n",
    "        legend_title=\"Producto / Modelo\",\n",
    "        template=\"ggplot2\"\n",
    "    )\n",
    "\n",
    "    # Etiquetas ejes\n",
    "    fig.update_xaxes(title_text=\"Turn\", row=2, col=1)\n",
    "    fig.update_xaxes(title_text=\"Turn\", row=2, col=2)\n",
    "    fig.update_yaxes(title_text=\"Demanda\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Demanda\", row=2, col=1)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b4d979",
   "metadata": {},
   "source": [
    "## Función para graficar los pronosticos de materia prima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b2932ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_colores_mp(elementos):\n",
    "    \"\"\"\n",
    "    Asigna colores únicos a cada elemento (producto o materia prima).\n",
    "    Usa una paleta de colores de Plotly.\n",
    "    \n",
    "    Parámetro:\n",
    "    - elementos: lista o conjunto de nombres\n",
    "    \n",
    "    Retorna:\n",
    "    - diccionario {elemento: color}\n",
    "    \"\"\"\n",
    "    elementos = sorted(list(set(elementos)))\n",
    "    paleta = px.colors.qualitative.Set2  # Puedes cambiar por Set1, Set2, Plotly, etc.\n",
    "    n_colores = len(paleta)\n",
    "\n",
    "    colores_mp = {\n",
    "        elemento: paleta[i % n_colores]\n",
    "        for i, elemento in enumerate(elementos)\n",
    "    }\n",
    "\n",
    "    return colores_mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dcb264f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficar_pronosticos_mp(df, resultados_mp, colores_mp):\n",
    "    \"\"\"\n",
    "    Grafica series de consumo real y pronóstico para materias primas.\n",
    "\n",
    "    Parámetros:\n",
    "    - df: DataFrame con columnas ['Turn', 'MATERIA_PRIMA', 'DEMANDA_MATERIA_PRIMA']\n",
    "    - resultados_por_serie: dict con claves = materia prima y valores con 'pronostico_final' y 'mejor_modelo'\n",
    "    - colores_mp: dict {materia_prima: color}\n",
    "    - lags: número de pasos de pronóstico\n",
    "    \"\"\"\n",
    "\n",
    "    elementos = sorted(df['MATERIA_PRIMA'].unique())\n",
    "    n = len(elementos)\n",
    "    cols = 3\n",
    "    rows = math.ceil(n / cols)\n",
    "\n",
    "    # Dividir nombres largos con salto de línea si exceden cierto número de caracteres\n",
    "    def ajustar_titulo(texto, max_len=30):\n",
    "        return \"<br>\".join(texto[i:i+max_len] for i in range(0, len(texto), max_len))\n",
    "\n",
    "    titulos = elementos\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=rows, cols=cols,\n",
    "        subplot_titles=titulos\n",
    "    )\n",
    "\n",
    "    showlegend_flag = True\n",
    "\n",
    "    for i, materia in enumerate(elementos):\n",
    "        row = (i // cols) + 1\n",
    "        col = (i % cols) + 1\n",
    "\n",
    "        fila = df[df['MATERIA_PRIMA'] == materia].tail(52 + lags)\n",
    "        color = colores_mp.get(materia, None)\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=fila['Turn'],\n",
    "                y=fila['DEMANDA_MATERIA_PRIMA'],\n",
    "                mode='lines',\n",
    "                name=materia,\n",
    "                line=dict(color=color),\n",
    "                showlegend=showlegend_flag\n",
    "            ),\n",
    "            row=row, col=col\n",
    "        )\n",
    "\n",
    "        if materia in resultados_mp:\n",
    "            pronostico_final = resultados_mp[materia][\"pronostico_final\"]\n",
    "            mejor_modelo = resultados_mp[materia][\"mejor_modelo\"]\n",
    "            lags = len(pronostico_final)  # Cantidad de pasos de pronóstico\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=pronostico_final.index,\n",
    "                    y=pronostico_final[mejor_modelo],\n",
    "                    mode='lines',\n",
    "                    name=f\"{materia} ({mejor_modelo})\",\n",
    "                    line=dict(dash='dot', color=color),\n",
    "                    showlegend=showlegend_flag\n",
    "                ),\n",
    "                row=row, col=col\n",
    "            )\n",
    "\n",
    "        showlegend_flag = False\n",
    "\n",
    "    # Disminuir tamaño de fuente de títulos individuales\n",
    "    for anotacion in fig['layout']['annotations']:\n",
    "        anotacion['font'] = dict(size=11)\n",
    "\n",
    "    fig.update_layout(\n",
    "        height=300 * rows, width=1200,\n",
    "        title_text=\"Consumo y Pronóstico por Materia Prima\",\n",
    "        showlegend=False,\n",
    "        legend_title=\"Materia Prima / Modelo\",\n",
    "        template=\"ggplot2\",\n",
    "        font=dict(size=12)  # Solo afecta ejes, leyenda, título general\n",
    "    )\n",
    "    fig.update_xaxes(title_text=\"Turn\")\n",
    "    fig.update_yaxes(title_text=\"Demanda\")\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea88ec01",
   "metadata": {},
   "source": [
    "# Funciones de Ayuda para Selección de pronósticos de Producto terminado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8c8437",
   "metadata": {},
   "source": [
    "## Creación de diccionario con series de tiempo producto-regional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2b236bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un diccionario con cada serie de tiempo de demanda por producto y regional\n",
    "def crear_dicc_pt(df):\n",
    "\n",
    "    \"\"\"\n",
    "    Crea un diccionario donde las claves son tuplas (REGIONAL, PRODUCTO)\n",
    "    y los valores son Series de DEMANDA indexadas por Turn.\n",
    "    \"\"\"\n",
    "    \n",
    "    series_dict_pt = {\n",
    "        (reg, prod): serie\n",
    "        for reg in df['REGIONAL'].unique()\n",
    "        for prod in df['PRODUCTO'].unique()\n",
    "        if not (serie := df[(df['REGIONAL'] == reg) & (df['PRODUCTO'] == prod)]\n",
    "                    .set_index('Turn')['DEMANDA']\n",
    "                    .sort_index()).empty\n",
    "    }\n",
    "\n",
    "    return series_dict_pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3306e5d",
   "metadata": {},
   "source": [
    "## Creación de diccionario con series de tiempo materia prima en mototrak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "30b0a8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un diccionario con cada serie de tiempo de demanda por materia prima\n",
    "def crear_dicc_mp(df_consumo):\n",
    "\n",
    "    \"\"\"\n",
    "    Crea un diccionario con df de materia prima explosionada,\n",
    "    y los valores son Series de DEMANDA indexadas por Turn.\n",
    "    \"\"\"\n",
    "\n",
    "    series_dict_mp = {\n",
    "        materia: serie\n",
    "        for materia in df_consumo['MATERIA_PRIMA'].unique()\n",
    "        if not (serie := df_consumo[df_consumo['MATERIA_PRIMA'] == materia]\n",
    "                        .set_index('Turn')['DEMANDA_MATERIA_PRIMA']\n",
    "                        .sort_index()).empty\n",
    "    }\n",
    "\n",
    "    return series_dict_mp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38503c0",
   "metadata": {},
   "source": [
    "## Backtesting\n",
    "Se hará backtesting desde n periodos hacia atras y generando múltiples pronósticos hacia adelante (lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "877d8ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_pronosticos_generico(series_dict, periodos_atras=48, lags=6):\n",
    "    \"\"\"\n",
    "    Aplica modelos de pronóstico sobre un diccionario de series univariadas.\n",
    "    Funciona tanto para productos terminados como materias primas.\n",
    "    \"\"\"\n",
    "\n",
    "    turnos = next(iter(series_dict.values())).index.tolist()\n",
    "    rango_turnos = turnos[-(periodos_atras + 1):]\n",
    "    resultados_por_serie = {}\n",
    "\n",
    "    # Widgets dinámicos solo si estás en Streamlit\n",
    "    progreso = st.empty() if USANDO_STREAMLIT else None\n",
    "    barra = st.progress(0) if USANDO_STREAMLIT else None\n",
    "    total = len(series_dict)\n",
    "\n",
    "    for i, (clave, serie) in enumerate(series_dict.items()):\n",
    "        if USANDO_STREAMLIT:\n",
    "            progreso.markdown(f\"👨‍💻 Analizando `{clave}`...\")\n",
    "            barra.progress((i + 1) / total)\n",
    "        else:\n",
    "            print(f\"👨‍💻 Analizando {clave}\")\n",
    "\n",
    "        resultados_hw, resultados_hw_13 = [], []\n",
    "        resultados_pm_3, resultados_pm_6, resultados_pm_12 = [], [], []\n",
    "\n",
    "        for j, fecha_corte in enumerate(rango_turnos):\n",
    "            serie_corte = serie[serie.index <= fecha_corte].copy()\n",
    "            indice_real = serie_corte.index.copy()\n",
    "            serie_corte.index = pd.RangeIndex(start=0, stop=len(serie_corte))\n",
    "\n",
    "            inicio_pronostico = fecha_corte + 1\n",
    "            fin_pronostico = inicio_pronostico + lags - 1\n",
    "\n",
    "            if len(serie_corte) >= 10:\n",
    "                try:\n",
    "                    modelo_hw = ExponentialSmoothing(serie_corte, trend='add', seasonal=None).fit()\n",
    "                    forecast_hw = modelo_hw.forecast(lags)\n",
    "                    forecast_hw.index = range(inicio_pronostico, fin_pronostico + 1)\n",
    "\n",
    "                    modelo_hw_13 = ExponentialSmoothing(\n",
    "                        serie_corte, trend='add', seasonal='add', seasonal_periods=13\n",
    "                    ).fit()\n",
    "                    forecast_hw_13 = modelo_hw_13.forecast(lags)\n",
    "                    forecast_hw_13.index = range(inicio_pronostico, fin_pronostico + 1)\n",
    "                except:\n",
    "                    forecast_hw = pd.Series([np.nan] * lags, index=range(inicio_pronostico, fin_pronostico + 1))\n",
    "                    forecast_hw_13 = pd.Series([np.nan] * lags, index=range(inicio_pronostico, fin_pronostico + 1))\n",
    "            else:\n",
    "                forecast_hw = pd.Series([np.nan] * lags, index=range(inicio_pronostico, fin_pronostico + 1))\n",
    "                forecast_hw_13 = pd.Series([np.nan] * lags, index=range(inicio_pronostico, fin_pronostico + 1))\n",
    "\n",
    "            serie_corte.index = indice_real\n",
    "\n",
    "            pm_3 = serie_corte.rolling(3).mean().iloc[-1] if len(serie_corte) >= 3 else np.nan\n",
    "            pm_6 = serie_corte.rolling(6).mean().iloc[-1] if len(serie_corte) >= 6 else np.nan\n",
    "            pm_12 = serie_corte.rolling(12).mean().iloc[-1] if len(serie_corte) >= 12 else np.nan\n",
    "\n",
    "            pm_3_series = pd.Series([pm_3] * lags, index=range(inicio_pronostico, fin_pronostico + 1))\n",
    "            pm_6_series = pd.Series([pm_6] * lags, index=range(inicio_pronostico, fin_pronostico + 1))\n",
    "            pm_12_series = pd.Series([pm_12] * lags, index=range(inicio_pronostico, fin_pronostico + 1))\n",
    "\n",
    "            demanda_real = serie.loc[inicio_pronostico:fin_pronostico]\n",
    "\n",
    "            df_comb = pd.DataFrame({\n",
    "                'real': demanda_real,\n",
    "                'hw': forecast_hw,\n",
    "                'hw_13': forecast_hw_13,\n",
    "                'pm_3': pm_3_series,\n",
    "                'pm_6': pm_6_series,\n",
    "                'pm_12': pm_12_series,\n",
    "            })\n",
    "\n",
    "            if j < len(rango_turnos) - 1:\n",
    "                df_comb = df_comb.dropna(subset=['real'])\n",
    "                resultados_hw.append(df_comb[['real', 'hw']])\n",
    "                resultados_hw_13.append(df_comb[['real', 'hw_13']])\n",
    "                resultados_pm_3.append(df_comb[['real', 'pm_3']])\n",
    "                resultados_pm_6.append(df_comb[['real', 'pm_6']])\n",
    "                resultados_pm_12.append(df_comb[['real', 'pm_12']])\n",
    "            else:\n",
    "                pronostico_final_hw = df_comb[['real', 'hw']]\n",
    "                pronostico_final_hw_13 = df_comb[['real', 'hw_13']]\n",
    "                pronostico_final_pm_3 = df_comb[['real', 'pm_3']]\n",
    "                pronostico_final_pm_6 = df_comb[['real', 'pm_6']]\n",
    "                pronostico_final_pm_12 = df_comb[['real', 'pm_12']]\n",
    "\n",
    "        modelos = {\n",
    "            'hw': (resultados_hw, pronostico_final_hw),\n",
    "            'hw_13': (resultados_hw_13, pronostico_final_hw_13),\n",
    "            'pm_3': (resultados_pm_3, pronostico_final_pm_3),\n",
    "            'pm_6': (resultados_pm_6, pronostico_final_pm_6),\n",
    "            'pm_12': (resultados_pm_12, pronostico_final_pm_12),\n",
    "        }\n",
    "\n",
    "        metricas_modelos = {}\n",
    "        for nombre_modelo, (resultados, _) in modelos.items():\n",
    "            if resultados:\n",
    "                df_resultado = pd.concat(resultados)\n",
    "                df_resultado[\"error\"] = df_resultado[\"real\"] - df_resultado[nombre_modelo]\n",
    "                df_resultado[\"error_abs\"] = df_resultado[\"error\"].abs()\n",
    "                suma_real = df_resultado[\"real\"].sum()\n",
    "                mae_porc = df_resultado[\"error_abs\"].sum() / suma_real\n",
    "                sesgo_porc = df_resultado[\"error\"].sum() / suma_real\n",
    "                score_porc = mae_porc + abs(sesgo_porc)\n",
    "                rmse = np.sqrt((df_resultado[\"error\"] ** 2).mean())\n",
    "            else:\n",
    "                mae_porc = np.nan\n",
    "                sesgo_porc = np.nan\n",
    "                score_porc = np.inf\n",
    "                rmse = np.nan\n",
    "\n",
    "            metricas_modelos[nombre_modelo] = {\n",
    "                \"mae_porc\": mae_porc,\n",
    "                \"sesgo_porc\": sesgo_porc,\n",
    "                \"score_porc\": round(score_porc, 3),\n",
    "                \"rmse\": rmse\n",
    "            }\n",
    "\n",
    "        df_metricas = pd.DataFrame(metricas_modelos).T.sort_values(\"score_porc\")\n",
    "        mejor_modelo = df_metricas.index[0]\n",
    "        pronostico_final = modelos[mejor_modelo][1]\n",
    "\n",
    "        resultados_por_serie[clave] = {\n",
    "            \"mejor_modelo\": mejor_modelo,\n",
    "            \"metricas\": df_metricas,\n",
    "            \"pronostico_final\": pronostico_final\n",
    "        }\n",
    "\n",
    "    return resultados_por_serie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480c482e",
   "metadata": {},
   "source": [
    "## Funciones de Ayuda para la generacion de reportes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ecc65a",
   "metadata": {},
   "source": [
    "### Reporte Producto Terminado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e0cb3c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_resumen_pt(resultados_pt):\n",
    "\n",
    "    \"\"\"\n",
    "    Genera un DataFrame resumen con los mejores modelos y pronósticos finales   \n",
    "    \"\"\"\n",
    "\n",
    "    # Construir DataFrame de resumen final\n",
    "    resumen_filas = []\n",
    "\n",
    "    for (regional, producto), datos in resultados_pt.items():\n",
    "        mejor_modelo = datos['mejor_modelo']\n",
    "        metricas = datos['metricas']\n",
    "        pronostico_final = datos['pronostico_final']\n",
    "\n",
    "        # Obtener métricas del mejor modelo\n",
    "        rmse_val = metricas.loc[mejor_modelo, 'rmse']\n",
    "        score_val = metricas.loc[mejor_modelo, 'score_porc']\n",
    "\n",
    "        # Extraer pronósticos del mejor modelo\n",
    "        pronostico = pronostico_final[mejor_modelo]\n",
    "\n",
    "        # Convertir índice a columnas de pronóstico: 1, 2, ..., N\n",
    "        fila = {\n",
    "            'REGIONAL': regional,\n",
    "            'PRODUCTO': producto,\n",
    "            'MODELO': mejor_modelo.upper(),  \n",
    "            'SCORE_PORC': f\"{round(score_val * 100, 1)}%\",                     \n",
    "            'RMSE': round(rmse_val, 1),\n",
    "        }\n",
    "\n",
    "        for i, (turno, valor) in enumerate(pronostico.items(), start=1):\n",
    "            fila[i] = round(valor, 0) if pd.notna(valor) else np.nan\n",
    "\n",
    "        resumen_filas.append(fila)\n",
    "\n",
    "    # Crear DataFrame final\n",
    "    df_resumen = pd.DataFrame(resumen_filas)\n",
    "\n",
    "    # Ordenar columnas: fijas + dinámicas (1, 2, ..., N)\n",
    "    cols_fijas = ['REGIONAL', 'PRODUCTO','MODELO', 'SCORE_PORC', 'RMSE']\n",
    "    cols_turnos = sorted([col for col in df_resumen.columns if isinstance(col, int)])\n",
    "    df_resumen = df_resumen[cols_fijas + cols_turnos]\n",
    "\n",
    "    # Mostrar\n",
    "    return df_resumen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd084bd",
   "metadata": {},
   "source": [
    "### Reporte Materia Prima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3a97fe7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_resumen_mp(resultados_mp):\n",
    "    \"\"\"\n",
    "    Genera un DataFrame resumen con los mejores modelos y pronósticos finales para materias primas\n",
    "    \"\"\"\n",
    "\n",
    "    resumen_filas = []\n",
    "\n",
    "    for producto, datos in resultados_mp.items():\n",
    "        mejor_modelo = datos['mejor_modelo']\n",
    "        metricas = datos['metricas']\n",
    "        pronostico_final = datos['pronostico_final']\n",
    "\n",
    "        # Obtener métricas del mejor modelo\n",
    "        rmse_val = metricas.loc[mejor_modelo, 'rmse']\n",
    "        score_val = metricas.loc[mejor_modelo, 'score_porc']\n",
    "\n",
    "        # Extraer pronósticos del mejor modelo\n",
    "        pronostico = pronostico_final[mejor_modelo]\n",
    "\n",
    "        fila = {\n",
    "            'PRODUCTO': producto,\n",
    "            'MODELO': mejor_modelo.upper(),\n",
    "            'SCORE_PORC': f\"{round(score_val * 100, 1)}%\",\n",
    "            'RMSE': round(rmse_val, 1),\n",
    "        }\n",
    "\n",
    "        for i, valor in enumerate(pronostico.tolist(), start=1):\n",
    "            fila[i] = round(valor, 0) if pd.notna(valor) else np.nan\n",
    "\n",
    "        resumen_filas.append(fila)\n",
    "\n",
    "    # Crear DataFrame\n",
    "    df_resumen = pd.DataFrame(resumen_filas)\n",
    "\n",
    "    # Ordenar columnas\n",
    "    cols_fijas = ['PRODUCTO', 'MODELO', 'SCORE_PORC', 'RMSE']\n",
    "    cols_turnos = sorted([col for col in df_resumen.columns if isinstance(col, int)])\n",
    "    df_resumen = df_resumen[cols_fijas + cols_turnos]\n",
    "\n",
    "    return df_resumen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6969d709",
   "metadata": {},
   "source": [
    "# Script de Ejecución Parte 1 - Producto Terminado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5f3908",
   "metadata": {},
   "source": [
    "# Define la carpeta donde están los archivos\n",
    "ruta_demandas = 'dataset/'\n",
    "df_agregado = cargar_demandas(ruta_demandas)\n",
    "\n",
    "# Define los productos a considerar\n",
    "productos = ['MOTO', 'CUATRIMOTO', 'TRACTOR']\n",
    "\n",
    "# Preprocesar los datos parte 1\n",
    "df_final = preprocesar_datos_parte_1(df_agregado, productos)\n",
    "\n",
    "# Preprocesar los datos parte 2\n",
    "df = preprocesar_datos_parte_2(df_final)\n",
    "\n",
    "# Mostrar el DataFrame final\n",
    "df\n",
    "\n",
    "# Definir cololres para los productos terminados\n",
    "colores_pt = {\n",
    "    'MOTO': 'salmon',\n",
    "    'CUATRIMOTO': 'navy',\n",
    "    'TRACTOR': 'darkcyan'\n",
    "}\n",
    "# Graficar la demanda de producto terminado\n",
    "#graficar_demanda_pt(df, colores_pt)\n",
    "\n",
    "# Crear diccionario con series de tiempo por producto y regional\n",
    "series_dict_pt = crear_dicc_pt(df)\n",
    "\n",
    "# Realizar pronósticos para las series de tiempo de producto terminado\n",
    "resultados_pt = crear_pronosticos_generico(series_dict_pt, periodos_atras=48, lags=6)\n",
    "\n",
    "# Graficar los pronósticos de producto terminado\n",
    "graficar_pronosticos_pt(df, resultados_pt, colores_pt)\n",
    "\n",
    "# Generar resumen de los resultados de pronósticos de producto terminado\n",
    "df_resumen = generar_resumen_pt(resultados_pt)\n",
    "display(df_resumen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedec11f",
   "metadata": {},
   "source": [
    "# Script de Ejecución Parte 2 - Materia Prima"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6a3c8f",
   "metadata": {},
   "source": [
    "# Cargar todas las hojas del archivo Excel\n",
    "ruta_data_maestra = r'dataset\\INFO_MAESTRA_BOM_TIEMPOS.xlsx'\n",
    "\n",
    "# Cargar los DataFrames de la data maestra\n",
    "df_bom_mp, df_m_d_o, df_transporte, df_almacenamiento = cargar_data_maestra(ruta_data_maestra)\n",
    "\n",
    "# Preprocesar los datos de materia prima\n",
    "df_bom_vertical = preprocesar_datos_mp(df_bom_mp)\n",
    "\n",
    "# Explosionar los datos de materia prima\n",
    "df_consumo = explosionar_mp(df, df_bom_vertical)\n",
    "\n",
    "# Crear un diccionario con series de tiempo de materia prima\n",
    "series_dict_mp = crear_dicc_mp(df_consumo)\n",
    "\n",
    "# Generar pronósticos para las series de tiempo de materia prima\n",
    "resultados_mp = crear_pronosticos_generico(series_dict_mp, periodos_atras=48, lags=12)\n",
    "\n",
    "# Generar colores para las materias primas\n",
    "colores_mp = generar_colores_mp(df_bom_vertical['MATERIA_PRIMA'].unique())\n",
    "\n",
    "# Graficar los pronósticos de materia prima\n",
    "graficar_pronosticos_mp(df_consumo, resultados_mp, colores_mp, lags=12)\n",
    "\n",
    "# Generar resumen de los resultados de pronósticos de materia prima\n",
    "generar_resumen_mp(resultados_mp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6183835f",
   "metadata": {},
   "source": [
    "# Front End Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f6da55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-30 21:53:36.307 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.309 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.310 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.310 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.312 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.312 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.313 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.314 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.315 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.316 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.317 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.318 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.319 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.320 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.320 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.321 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.323 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.323 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.324 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.325 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.325 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.325 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.326 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.326 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.327 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.328 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.329 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.329 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.330 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.331 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.332 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.333 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.333 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.334 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.335 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.335 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.336 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.336 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.337 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.338 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.339 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.339 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.340 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.341 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.341 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.342 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.342 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.343 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.343 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.344 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.344 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-30 21:53:36.345 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "st.set_page_config(page_title=\"App de Pronósticos Mototrak\", layout=\"wide\")\n",
    "\n",
    "st.title(\"App de Pronósticos para Producto Terminado y Materia Prima\")\n",
    "#pestaña_pt, pestaña_mp = st.tabs([\"Pronósticos PT\", \"Pronósticos MP\"])\n",
    "seccion = st.sidebar.radio(\"Selecciona sección\", [\"Pronósticos PT\", \"Pronósticos MP\"])\n",
    "# ----------------------------\n",
    "# PESTAÑA PRODUCTO TERMINADO\n",
    "# ----------------------------\n",
    "if seccion == \"Pronósticos PT\":\n",
    "    st.subheader(\"Cargar archivos de demanda por región\")\n",
    "    archivo_norte = st.file_uploader(\"Archivo demanda NORTE\", type=[\"csv\"])\n",
    "    archivo_centro = st.file_uploader(\"Archivo demanda CENTRO\", type=[\"csv\"])\n",
    "    archivo_sur = st.file_uploader(\"Archivo demanda SUR\", type=[\"csv\"])\n",
    "\n",
    "    periodos_atras_pt = st.number_input(\"Periodos hacia atrás para backtesting (PT)\", min_value=1, max_value=60, value=12)\n",
    "    lags_pt = st.number_input(\"Cantidad de periodos a pronosticar (lags PT)\", min_value=1, max_value=24, value=6)\n",
    "\n",
    "    if archivo_norte and archivo_centro and archivo_sur:\n",
    "        productos = ['MOTO', 'CUATRIMOTO', 'TRACTOR']\n",
    "        df_agregado = cargar_demandas_por_region(archivo_norte, archivo_centro, archivo_sur)\n",
    "        df_final = preprocesar_datos_parte_1(df_agregado, productos)\n",
    "        df = preprocesar_datos_parte_2(df_final)\n",
    "        st.session_state[\"df\"] = df\n",
    "\n",
    "        colores_pt = {'MOTO': 'salmon', 'CUATRIMOTO': 'navy', 'TRACTOR': 'darkcyan'}\n",
    "        series_dict_pt = crear_dicc_pt(df)\n",
    "\n",
    "        if st.button(\"Generar pronóstico de PT\"):\n",
    "          \n",
    "            resultados_pt = crear_pronosticos_generico(series_dict_pt, periodos_atras_pt, lags_pt)\n",
    "            df_resumen_pt = generar_resumen_pt(resultados_pt)\n",
    "\n",
    "            st.session_state['resultados_pt'] = resultados_pt\n",
    "            st.session_state['df_resumen_pt'] = df_resumen_pt\n",
    "\n",
    "            fig = graficar_pronosticos_pt(df, resultados_pt, colores_pt)\n",
    "            st.session_state['fig_pt'] = fig\n",
    "\n",
    "    # Mostrar resultados si ya existen\n",
    "    if 'df_resumen_pt' in st.session_state:\n",
    "        st.subheader(\"Resumen del pronóstico PT\")\n",
    "        st.dataframe(st.session_state['df_resumen_pt'], use_container_width=True)\n",
    "\n",
    "        # Reconstruir gráfica si no está en session_state\n",
    "        if 'fig_pt' not in st.session_state:\n",
    "            st.session_state['fig_pt'] = graficar_pronosticos_pt(\n",
    "                st.session_state['df'],\n",
    "                st.session_state['resultados_pt'],\n",
    "                {'MOTO': 'salmon', 'CUATRIMOTO': 'navy', 'TRACTOR': 'darkcyan'}\n",
    "            )\n",
    "\n",
    "        st.plotly_chart(st.session_state['fig_pt'], use_container_width=True)\n",
    "\n",
    "        buffer_pt = io.BytesIO()\n",
    "        st.session_state['df_resumen_pt'].to_excel(buffer_pt, index=False)\n",
    "        st.download_button(\n",
    "            \"📥 Descargar resumen PT en Excel\",\n",
    "            data=buffer_pt.getvalue(),\n",
    "            file_name=\"resumen_pt.xlsx\"\n",
    "        )\n",
    "\n",
    "# ----------------------------\n",
    "# PESTAÑA MATERIA PRIMA\n",
    "# ----------------------------\n",
    "elif seccion == \"Pronósticos MP\":\n",
    "    st.subheader(\"Cargar archivo maestro de datos\")\n",
    "    archivo_maestro = st.file_uploader(\"Archivo Excel (Info Maestra)\", type=[\"xlsx\"])\n",
    "\n",
    "    if archivo_maestro:\n",
    "        df_bom_mp, df_m_d_o, df_transporte, df_almacenamiento = cargar_data_maestra(archivo_maestro)\n",
    "        df_bom_vertical = preprocesar_datos_mp(df_bom_mp)\n",
    "        st.session_state[\"df_bom_vertical\"] = df_bom_vertical  # 💾 Guardar en session_state\n",
    "\n",
    "        if st.button(\"Ejecutar explosión de materiales\"):\n",
    "            try:\n",
    "                if \"df\" not in st.session_state:\n",
    "                    st.warning(\"Primero debes generar el pronóstico de Producto Terminado.\")\n",
    "                    st.stop()\n",
    "\n",
    "                df = st.session_state[\"df\"]\n",
    "                df_consumo = explosionar_mp(df, df_bom_vertical)\n",
    "                st.session_state[\"df_consumo\"] = df_consumo  # 💾 Guardar en session_state\n",
    "                st.success(\"Explosión realizada con éxito\")\n",
    "            except Exception as e:\n",
    "                st.error(f\"Error durante la explosión de materiales: {e}\")\n",
    "\n",
    "        # Parámetros visibles siempre que haya datos disponibles\n",
    "        if \"df_consumo\" in st.session_state and \"df_bom_vertical\" in st.session_state:\n",
    "            periodos_atras_mp = st.number_input(\"Periodos hacia atrás para backtesting (MP)\", min_value=1, max_value=60, value=12)\n",
    "            lags_mp = st.number_input(\"Cantidad de periodos a pronosticar (lags MP)\", min_value=1, max_value=24, value=6)\n",
    "\n",
    "            if st.button(\"Generar pronóstico de MP\"):\n",
    "                try:\n",
    "                    df_consumo = st.session_state[\"df_consumo\"]\n",
    "                    df_bom_vertical = st.session_state[\"df_bom_vertical\"]\n",
    "\n",
    "                    series_dict_mp = crear_dicc_mp(df_consumo)                  \n",
    "                    resultados_mp = crear_pronosticos_generico(series_dict_mp, periodos_atras_mp, lags_mp)\n",
    "                    df_resumen_mp = generar_resumen_mp(resultados_mp)\n",
    "\n",
    "                    st.session_state['resultados_mp'] = resultados_mp\n",
    "                    st.session_state['df_resumen_mp'] = df_resumen_mp\n",
    "\n",
    "                    colores_mp = generar_colores_mp(df_bom_vertical['MATERIA_PRIMA'].unique())\n",
    "                    st.session_state['colores_mp'] = colores_mp\n",
    "                    fig = graficar_pronosticos_mp(df_consumo, resultados_mp, colores_mp, lags=lags_mp)\n",
    "                    \n",
    "                    st.session_state['fig_mp'] = fig\n",
    "                    #st.dataframe(df_resumen_mp, use_container_width=True)\n",
    "\n",
    "\n",
    "\n",
    "                except Exception as e:\n",
    "                    st.error(f\"Error durante el pronóstico: {e}\")\n",
    "\n",
    "    # Mostrar resultados si ya existen\n",
    "    if 'df_resumen_mp' in st.session_state:\n",
    "        st.subheader(\"Resumen del pronóstico MP\")\n",
    "        st.dataframe(st.session_state['df_resumen_mp'], use_container_width=True)\n",
    "\n",
    "        # Reconstruir gráfica si no está en session_state\n",
    "        if 'fig_mp' not in st.session_state:\n",
    "            st.session_state['fig_mp'] = graficar_pronosticos_mp(\n",
    "                st.session_state['df'],\n",
    "                st.session_state['resultados_mp'],\n",
    "                st.session_state['colores_mp']\n",
    "            )\n",
    "\n",
    "        st.plotly_chart(st.session_state['fig_mp'], use_container_width=True)\n",
    "\n",
    "        buffer_mp = io.BytesIO()\n",
    "        st.session_state['df_resumen_mp'].to_excel(buffer_mp, index=False)\n",
    "        st.download_button(\n",
    "            \"📥 Descargar resumen MP en Excel\",\n",
    "            data=buffer_mp.getvalue(),\n",
    "            file_name=\"resumen_mp.xlsx\"\n",
    "        )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (entorno_v_log)",
   "language": "python",
   "name": "entorno_v_log"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
