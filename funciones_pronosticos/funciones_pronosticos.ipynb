{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40bdfa2a-2381-4daa-81f9-82cbacb597db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing, ExponentialSmoothing\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "from statsmodels.tsa.seasonal import MSTL\n",
    "from math import sqrt\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ab109f-4935-4d58-acb6-88f152f00446",
   "metadata": {},
   "source": [
    "# Funciones de ayuda pronosticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4126f177-9dee-483d-82a3-5badfa1315bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_columnas_error(df):\n",
    "    \n",
    "    df['ERROR'] = df['DEMANDA'] - df['FORECAST'] # Error\n",
    "    df['ABS_ERROR'] = df['ERROR'].abs() # Error Absoluto\n",
    "    df['ERROR_PORC'] = np.where(df['DEMANDA'] == 0, 2, df['ABS_ERROR'] / df['DEMANDA']) # Error porcentual, devuelve 200% si la demanda es 0\n",
    "    df['ERROR_CUADRADO'] = df['ERROR'] ** 2 # Error al cuadrado\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b3fabdb-5530-4a86-b156-dd15c7efd6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_error(df):\n",
    "    df['MAE%'] = df['ABS_ERROR']/df['DEMANDA']\n",
    "    df['SESGO%'] = df['ERROR']/df['DEMANDA']\n",
    "    df['SCORE%'] = df['MAE%'] + df['SESGO%'].abs()\n",
    "    if 'ERROR_CUADRADO_suma' in df.columns:\n",
    "        df['RMSE'] = np.sqrt(df['ERROR_CUADRADO_suma'] / df['ERROR_CUADRADO_cuenta'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2c077f4-454f-41b1-9074-8b096e116289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metricas_error(df, imprimir):\n",
    "     \n",
    "    # Verificar si el total de la demanda es 0\n",
    "    if df['DEMANDA'].sum() == 0:\n",
    "        sesgo_porc = 2\n",
    "        mae_porc = 2\n",
    "        score = 2\n",
    "    else:\n",
    "        sesgo_porc = df['ERROR'].sum() / df['DEMANDA'].sum()\n",
    "        mae_porc = df['ABS_ERROR'].sum() / df['DEMANDA'].sum()\n",
    "        score = mae_porc + abs(sesgo_porc)\n",
    "    \n",
    "    rmse = np.sqrt(df['ERROR_CUADRADO'].mean())\n",
    "        # Muestra los resultados formateados\n",
    "    if imprimir == 1:\n",
    "        print('MAE% modelo: {:.2%}'.format(mae_porc))\n",
    "        print('Sesgo% modelo: {:.2%}'.format(sesgo_porc))\n",
    "        print('Score modelo: {:.2%}'.format(score))\n",
    "        print('RMSE modelo: {:.1f}'.format(rmse))\n",
    "   \n",
    "    return sesgo_porc, mae_porc, rmse, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd3e8188-8387-497e-bde1-05458d0e009e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kpi_error_sku(df):\n",
    "    \n",
    "    if df is None:\n",
    "        return None, None, None\n",
    "        \n",
    "    # Definicion de fechas de testeo\n",
    "    if 'CONSECUTIVO' in df.columns:\n",
    "        fecha_fin_testeo = df['CONSECUTIVO'].max()\n",
    "        fecha_inicio_testeo = df['CONSECUTIVO'].min()\n",
    "    else:    \n",
    "        fecha_fin_testeo = df['Turn'].max()\n",
    "        fecha_inicio_testeo = df['Turn'].min()\n",
    "\n",
    "    # Crear columnas de error para cada pronostico generado\n",
    "    df_test = crear_columnas_error(df)\n",
    "\n",
    "    # Imprimir informacion de los periodos evaluados\n",
    "    print('Periodo de Evaluacion desde:')\n",
    "    if 'CONSECUTIVO' in df.columns:\n",
    "        print(f\"\\033[1m{df_test['CONSECUTIVO'].min()} hasta {df_test['CONSECUTIVO'].max()}\\033[0m\") #\\033[1m{}\\033[0m muestra la linea en negrilla\n",
    "    else:\n",
    "        print(f\"\\033[1m{df_test['Turn'].min()} hasta {df_test['Turn'].max()}\\033[0m\") #\\033[1m{}\\033[0m muestra la linea en negrilla\n",
    "    \n",
    "    # Calcular metricas de error\n",
    "    sesgo_porc, mae_porc, rmse, score = metricas_error(df_test, imprimir=1)\n",
    "    \n",
    "    # Agrupar df por sku\n",
    "    grupo_sku_error = df_test.groupby(['PRODUCTO','REGIONAL'], observed=True).agg({\n",
    "                                                            'DEMANDA': 'sum',\n",
    "                                                            'ERROR': 'sum',\n",
    "                                                            'ABS_ERROR': 'sum',\n",
    "                                                            'ERROR_CUADRADO': ['sum', 'count'],\n",
    "                                                            }).reset_index()\n",
    "\n",
    "    # Renombrar columnas\n",
    "    grupo_sku_error.columns = ['PRODUCTO', 'REGIONAL','DEMANDA', 'ERROR', 'ABS_ERROR', \n",
    "                             'ERROR_CUADRADO_suma', 'ERROR_CUADRADO_cuenta']\n",
    "    \n",
    "    # Calcular MAE% y Sesgo% de datos agregados por sku\n",
    "    grupo_sku_error = calcular_error(grupo_sku_error)\n",
    "    \n",
    "    # Ordenar el DataFrame por 'SCORE%' en orden ascendente\n",
    "    grupo_sku_error = grupo_sku_error.sort_values(by='SCORE%')\n",
    "    \n",
    "    # Aplicar formato porcentaje\n",
    "    formatted_columns = grupo_sku_error[['MAE%', 'SESGO%', 'SCORE%']].map(lambda x: f'{x * 100:.2f}%')\n",
    "    \n",
    "    # Concatenar la columna \"PRODUCTO\" sin formatear con las columnas formateadas\n",
    "    grupo_sku_error_formato = pd.concat([grupo_sku_error[['PRODUCTO','REGIONAL']], formatted_columns], axis=1)\n",
    "    \n",
    "    # Mostrar el resultado\n",
    "    display(grupo_sku_error_formato)\n",
    "\n",
    "    # Agrupar por PRODUCTO y por Lag para almacenar RMSE\n",
    "    grupo_sku_lag_error = df_test.groupby(['PRODUCTO', 'REGIONAL','LAG'], observed=True).agg({\n",
    "                                                            'DEMANDA': 'sum',\n",
    "                                                            'ERROR': 'sum',\n",
    "                                                            'ABS_ERROR': 'sum',\n",
    "                                                            'ERROR_CUADRADO': ['sum', 'count'],\n",
    "                                                            }).reset_index()\n",
    "\n",
    "    # Renombrar columnas\n",
    "    grupo_sku_lag_error.columns = ['PRODUCTO','REGIONAL','LAG', 'DEMANDA', 'ERROR', 'ABS_ERROR', \n",
    "                             'ERROR_CUADRADO_suma', 'ERROR_CUADRADO_cuenta']\n",
    "    \n",
    "    # Calcular MAE% y Sesgo% de datos agregados por lag\n",
    "    grupo_sku_lag_error = calcular_error(grupo_sku_lag_error)\n",
    "\n",
    "    # Calcular error rmse por lag\n",
    "    rmse_sku_lag = grupo_sku_lag_error[['PRODUCTO','REGIONAL','LAG','RMSE']]\n",
    "    \n",
    "    # Agrupar por PRODUCTO para almacenar RMSE\n",
    "    #df_test['Mes'] = df_test.index.month\n",
    "    grupo_sku_mes_error = df_test.groupby(['PRODUCTO', \n",
    "                                           'REGIONAL'\n",
    "                                          ], observed=True).agg({\n",
    "                                                            'DEMANDA': 'sum',\n",
    "                                                            'ERROR': 'sum',\n",
    "                                                            'ABS_ERROR': 'sum',\n",
    "                                                            'ERROR_CUADRADO': ['sum', 'count'],\n",
    "                                                            }).reset_index()\n",
    "    \n",
    "    # Renombrar columnas\n",
    "    grupo_sku_mes_error.columns = ['PRODUCTO',\n",
    "                                  'REGIONAL', \n",
    "                                   'DEMANDA', 'ERROR', 'ABS_ERROR', \n",
    "                             'ERROR_CUADRADO_suma', 'ERROR_CUADRADO_cuenta']\n",
    "\n",
    "    # Calcular error rmse por PRODUCTO\n",
    "    grupo_sku_mes_error = calcular_error(grupo_sku_mes_error)\n",
    "\n",
    "    # Filtrar las columnas para mejor visualizacion\n",
    "    rmse_sku_mes = grupo_sku_mes_error[['PRODUCTO',\n",
    "                                        'REGIONAL',\n",
    "                                        'RMSE']]\n",
    "    \n",
    "    return grupo_sku_error_formato, rmse_sku_lag, rmse_sku_mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0f25d0e-c64b-4904-8929-8d0f95c79355",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kpi_error_lag(df):\n",
    "    \n",
    "    if df is None:\n",
    "        return None, None\n",
    "    # Definicion de fechas de testeo\n",
    "    if 'CONSECUTIVO' in df.columns:\n",
    "        fecha_fin_testeo = df['CONSECUTIVO'].max()\n",
    "        fecha_inicio_testeo = df['CONSECUTIVO'].min()\n",
    "    else:    \n",
    "        fecha_fin_testeo = df['Turn'].max()\n",
    "        fecha_inicio_testeo = df['Turn'].min()\n",
    "    \n",
    "    # Crear columnas de error  \n",
    "    df_test = crear_columnas_error(df)\n",
    "    print('Periodo de Evaluacion desde:')   \n",
    "    if 'CONSECUTIVO' in df.columns:\n",
    "        print(f\"\\033[1m{df_test['CONSECUTIVO'].min()} hasta {df_test['CONSECUTIVO'].max()}\\033[0m\") #\\033[1m{}\\033[0m muestra la linea en negrilla\n",
    "    else:\n",
    "        print(f\"\\033[1m{df_test['Turn'].min()} hasta {df_test['Turn'].max()}\\033[0m\") #\\033[1m{}\\033[0m muestra la linea en negrilla\n",
    "\n",
    "    # Calcular loas metricas de error\n",
    "    sesgo_porc, mae_porc, rmse, score = metricas_error(df_test, imprimir=1)\n",
    "    \n",
    "    # Agrupar df por mes\n",
    "    grupo_mes_error = df_test.groupby(['LAG']).agg({\n",
    "                                                            'DEMANDA': 'sum',\n",
    "                                                            'ERROR': 'sum',\n",
    "                                                            'ABS_ERROR': 'sum',\n",
    "                                                            'ERROR_CUADRADO': ['sum', 'count'],\n",
    "                                                            }).reset_index()\n",
    "\n",
    "    # Renombrar columnas\n",
    "    grupo_mes_error.columns = ['LAG', 'DEMANDA', 'ERROR', 'ABS_ERROR', \n",
    "                             'ERROR_CUADRADO_suma', 'ERROR_CUADRADO_cuenta']\n",
    "    \n",
    "    # Calcular MAE% y Sesgo% de datos agregados por mes\n",
    "    grupo_mes_error = calcular_error(grupo_mes_error)\n",
    "    \n",
    "    # Aplicar formato porcentaje\n",
    "    formatted_columns = grupo_mes_error[['MAE%', 'SESGO%', 'SCORE%']].map(lambda x: f'{x * 100:.2f}%')\n",
    "    \n",
    "    # Concatenar la columna \"Lag\" sin formatear con las columnas formateadas\n",
    "    grupo_mes_error_formato = pd.concat([grupo_mes_error[['LAG']], formatted_columns], axis=1)\n",
    "    \n",
    "    # Mostrar el resultado\n",
    "    display(grupo_mes_error_formato)\n",
    "\n",
    "    # Agrupar por PRODUCTO y por Lag para almacenar RMSE\n",
    "    grupo_sku_lag_error = df_test.groupby(['PRODUCTO','REGIONAL', 'LAG'], observed=True).agg({\n",
    "                                                            'DEMANDA': 'sum',\n",
    "                                                            'ERROR': 'sum',\n",
    "                                                            'ABS_ERROR': 'sum',\n",
    "                                                            'ERROR_CUADRADO': ['sum', 'count'],\n",
    "                                                            }).reset_index()\n",
    "\n",
    "    # Renombrar columnas\n",
    "    grupo_sku_lag_error.columns = ['PRODUCTO','REGIONAL', 'LAG', 'DEMANDA', 'ERROR', 'ABS_ERROR', \n",
    "                             'ERROR_CUADRADO_suma', 'ERROR_CUADRADO_cuenta']\n",
    "\n",
    "    # Calcular columnas de error por lag\n",
    "    grupo_sku_lag_error = calcular_error(grupo_sku_lag_error)\n",
    "\n",
    "    # Filtrar columnas para mejor visualizacion\n",
    "    rmse_sku_lag = grupo_sku_lag_error[['PRODUCTO', 'REGIONAL','LAG','RMSE']]\n",
    "    \n",
    "    return grupo_mes_error_formato, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "690167de-bfd2-455a-acde-156b455f5fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agrupar_por_producto(df):\n",
    "    grupo_sku_error = df.groupby(['PRODUCTO','REGIONAL'], observed=True).agg({\n",
    "                                                                'DEMANDA': 'sum',\n",
    "                                                                'ERROR': 'sum',\n",
    "                                                                'ABS_ERROR': 'sum',\n",
    "                                                                'ERROR_CUADRADO': ['sum', 'count'],\n",
    "                                                                }).reset_index()\n",
    "    grupo_sku_error.columns = ['PRODUCTO','REGIONAL', 'DEMANDA', 'ERROR', 'ABS_ERROR', \n",
    "                                 'ERROR_CUADRADO_suma', 'ERROR_CUADRADO_cuenta']\n",
    "    \n",
    "    # Calcular MAE% y Sesgo% de datos agregados por sku\n",
    "    grupo_sku_error = calcular_error(grupo_sku_error)\n",
    "    grupo_sku_error = grupo_sku_error[['PRODUCTO','REGIONAL','MAE%',\t'SESGO%',\t'SCORE%',\t'RMSE']]\n",
    "    \n",
    "    # Agrupar por PRODUCTO y por Lag \n",
    "    grupo_sku_lag_error = df.groupby(['PRODUCTO','REGIONAL', 'LAG'], observed=True).agg({\n",
    "                                                            'DEMANDA': 'sum',\n",
    "                                                            'ERROR': 'sum',\n",
    "                                                            'ABS_ERROR': 'sum',\n",
    "                                                            'ERROR_CUADRADO': ['sum', 'count'],\n",
    "                                                            }).reset_index()\n",
    "    \n",
    "    grupo_sku_lag_error.columns = ['PRODUCTO','REGIONAL','LAG', 'DEMANDA', 'ERROR', 'ABS_ERROR', \n",
    "                             'ERROR_CUADRADO_suma', 'ERROR_CUADRADO_cuenta']\n",
    "    \n",
    "    grupo_sku_lag_error = calcular_error(grupo_sku_lag_error)\n",
    "    grupo_sku_lag_error = grupo_sku_lag_error[['PRODUCTO','REGIONAL','LAG','MAE%',\t'SESGO%',\t'SCORE%',\t'RMSE']]\n",
    "\n",
    "    # Pivotear el DataFrame de lag\n",
    "    pivoted_lags = grupo_sku_lag_error.pivot(index=['PRODUCTO','REGIONAL'], columns='LAG', values='SCORE%')\n",
    "    pivoted_lags.columns = [f\"score_{col}\" for col in pivoted_lags.columns]\n",
    "    \n",
    "    # Unir con el DataFrame principal\n",
    "    tabla_final = grupo_sku_error.merge(pivoted_lags, on=['PRODUCTO','REGIONAL'], how='left')\n",
    "    \n",
    "    # Renombrar columnas para cumplir con el formato\n",
    "    tabla_final = tabla_final.rename(columns={'MAE%': 'mae_porc', 'SESGO%': 'sesgo_porc', 'SCORE%': 'score', 'RMSE': 'rmse'})\n",
    "    \n",
    "    return tabla_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96366b3c-d901-4287-9e48-b1b27c01d286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adicionar_nombre_modelo_serie_tiempo(df, nombre_modelo):\n",
    "    if df is None:\n",
    "        return None\n",
    "    df['MODELO'] = nombre_modelo\n",
    "    df = df[['PRODUCTO','REGIONAL','Turn','FORECAST','LAG','MODELO']]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a16228c-8683-448b-b6db-2202a531d0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_reporte_error_skus(modelos):\n",
    "    return {modelo: globals()[f'grupo_sku_error_formato_{modelo}'] for modelo in modelos}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2beca0b1-b69d-4451-bac2-bbdc377c2ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para pronosticos por meses\n",
    "def comparar_y_graficar_modelos(reporte_error_skus):\n",
    "    # Crear el DataFrame base con la columna 'PRODUCTO'\n",
    "    df_final = reporte_error_skus['pms'][['PRODUCTO','REGIONAL']].copy()\n",
    "    \n",
    "    # Iterar sobre los modelos para combinarlos en df_final\n",
    "    for nombre_modelo, df in reporte_error_skus.items():\n",
    "        df_final = df_final.merge(\n",
    "            #df[['PRODUCTO', 'MAE%']].rename(columns={'MAE%': nombre_modelo}), \n",
    "            df[['PRODUCTO','REGIONAL', 'SCORE%']].rename(columns={'SCORE%': nombre_modelo}),\n",
    "            on=['PRODUCTO', 'REGIONAL'],\n",
    "            how='left'\n",
    "        )\n",
    "        df['MODELO'] = nombre_modelo\n",
    "        \n",
    "    # Remover simbolos de porcentaje y convertir columnas a valores numericos\n",
    "    modelos_cols = list(reporte_error_skus.keys())\n",
    "    df_final[modelos_cols] = df_final[modelos_cols].apply(lambda col: abs(col.str.rstrip('%').astype(float)))\n",
    "    \n",
    "    # Identificar la columna con el valor minimo para cada fila\n",
    "    df_final['MEJOR_MODELO'] = df_final[modelos_cols].idxmin(axis=1)\n",
    "    #dejar una copia sin formato porcentaje\n",
    "    df_minimos = df_final.copy()\n",
    "    # Dar formato a las columnas con un decimal y agregar el simbolo %\n",
    "    df_final[modelos_cols] = df_final[modelos_cols].apply(lambda x: x.map('{:.1f}%'.format))\n",
    "    \n",
    "    # Contar cuantas veces el modelo es el mejor\n",
    "    report = df_final['MEJOR_MODELO'].value_counts()\n",
    "    \n",
    "    # Preparar y crear la grafica de dona\n",
    "    fig1 = go.Figure(data=[go.Pie(\n",
    "        labels=report.index, \n",
    "        values=report.values, \n",
    "        hole=0.4,  \n",
    "        textinfo='percent+label',  \n",
    "        marker=dict(colors=px.colors.qualitative.Plotly)  \n",
    "    )])\n",
    "    \n",
    "    # Actualizar Layout de la grafica\n",
    "    fig1.update_layout(\n",
    "        title='Distribucion de Mejor Modelo por SKUs',\n",
    "        title_x=0.5,  \n",
    "        template='plotly_white'  \n",
    "    )\n",
    "   \n",
    "\n",
    "\n",
    "    # Concatenar todos los DataFrames en uno solo\n",
    "    df_errores_totales = pd.concat(reporte_error_skus.values(), ignore_index=True) \n",
    "    \n",
    "    return df_minimos, df_final, reporte_error_skus, fig1, df_errores_totales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c23ad3fa-b765-44c1-b0ed-b55038ac6d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenar_forecasts_pronosticos(modelos):\n",
    "    # Filtrar los DataFrames válidos (no None y no vacíos)\n",
    "    dfs_validos = [\n",
    "        globals()[f'df_forecast_final_{modelo}']\n",
    "        for modelo in modelos\n",
    "        if globals()[f'df_forecast_final_{modelo}'] is not None and not globals()[f'df_forecast_final_{modelo}'].empty\n",
    "    ]\n",
    "    \n",
    "    # Verificar si hay DataFrames válidos\n",
    "    if not dfs_validos:\n",
    "        print(\"No hay pronósticos válidos para concatenar.\")\n",
    "        return None\n",
    "\n",
    "    # Concatenar todos los DataFrames válidos en uno solo\n",
    "    df_todos_pronosticos = pd.concat(dfs_validos)\n",
    "\n",
    "    # Asegurar que la columna 'PRODUCTO' sea de tipo string\n",
    "    df_todos_pronosticos['PRODUCTO'] = df_todos_pronosticos['PRODUCTO'].astype(str)\n",
    "\n",
    "    return df_todos_pronosticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c62ae007-1e47-4b33-89a8-4ecd21b84702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenar_rmse(modelos):\n",
    "    # Obtener los DataFrames dinámicamente usando la lista de modelos\n",
    "    dfs_error = []\n",
    "    \n",
    "    for modelo in modelos:\n",
    "        # Obtener el DataFrame para cada modelo\n",
    "        df = globals().get(f'rmse_sku_mes_{modelo}')\n",
    "        \n",
    "        # Verificar si el DataFrame es None o está vacío\n",
    "        if df is None or df.empty:\n",
    "            print(f\"El modelo {modelo} fue ignorado porque no tiene datos.\")\n",
    "            continue\n",
    "        \n",
    "        # Añadir una columna 'MODELO' con el nombre del modelo\n",
    "        df['MODELO'] = modelo\n",
    "        #f['RMSE'] = np.ceil(df['RMSE']).astype(int)\n",
    "        #df['RMSE'] = df['RMSE'].astype(int)\n",
    "        # Añadir el DataFrame a la lista\n",
    "        dfs_error.append(df)\n",
    "    \n",
    "    # Verificar si hay DataFrames para concatenar\n",
    "    if not dfs_error:\n",
    "        print(\"No hay datos para concatenar.\")\n",
    "        return pd.DataFrame()  # Devuelve un DataFrame vacío\n",
    "    \n",
    "    # Concatenar todos los DataFrames en uno solo\n",
    "    df_todos_rmse = pd.concat(dfs_error, ignore_index=True)\n",
    "    \n",
    "    # Asegurar que la columna 'CODIGO' sea de tipo string\n",
    "    df_todos_rmse['PRODUCTO'] = df_todos_rmse['PRODUCTO'].astype(str)\n",
    "\n",
    "    return df_todos_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "794488e4-7c12-44b8-9efd-88c7889d0880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_mejor_pronostico(df_minimos, df_todos_pronosticos, df_errores_totales, df_todos_rmse):\n",
    "    # Crear una lista para almacenar los DataFrames filtrados\n",
    "    lista_filtrados = [\n",
    "        df_todos_pronosticos[\n",
    "            (df_todos_pronosticos['PRODUCTO'] == row['PRODUCTO']) &\n",
    "            (df_todos_pronosticos['REGIONAL'] == row['REGIONAL']) &\n",
    "            (df_todos_pronosticos['MODELO'] == row['MEJOR_MODELO'])\n",
    "        ]\n",
    "        for _, row in df_minimos.iterrows()\n",
    "    ]\n",
    "    \n",
    "    # Concatenar todos los DataFrames filtrados\n",
    "    df_pronosticos_mejor_modelo = pd.concat(lista_filtrados)\n",
    "    \n",
    "    # Pivotear el resultado para mostrar el forecast por Código, Modelo y Fecha\n",
    "    #df_pronosticos_n_periodos = df_pronosticos_mejor_modelo.pivot_table(index=[\"PRODUCTO\", \"MODELO\"], columns=\"FECHA\", values=\"FORECAST\")#.reset_index()\n",
    "    df_pronosticos_finales = df_pronosticos_mejor_modelo.pivot_table(index=[\"PRODUCTO\",'REGIONAL', \"MODELO\"], columns=\"Turn\", values=\"FORECAST\").reset_index()\n",
    "    # Realizamos un merge para agregar las columnas coincidiendo por PRODUCTO y MODELO\n",
    "    # Realiza el merge entre ambos DataFrames en las claves 'PRODUCTO' y 'MODELO'\n",
    "    df_merged = pd.merge(\n",
    "        df_pronosticos_finales, \n",
    "        df_errores_totales[['PRODUCTO','REGIONAL', 'MODELO', 'MAE%', 'SESGO%', 'SCORE%']], \n",
    "        on=['PRODUCTO','REGIONAL', 'MODELO'], \n",
    "        how='left'\n",
    "    )\n",
    "    df_merged_rmse = pd.merge(\n",
    "        df_merged, \n",
    "        df_todos_rmse[['PRODUCTO', 'REGIONAL', 'MODELO', 'RMSE']], \n",
    "        on=['PRODUCTO','REGIONAL', 'MODELO'], \n",
    "        how='left'\n",
    "    )\n",
    " \n",
    "    # Inserta las columnas en las posiciones deseadas\n",
    "    df_merged_rmse.insert(0, 'MAE%', df_merged_rmse.pop('MAE%'))\n",
    "    df_merged_rmse.insert(1, 'SESGO%', df_merged_rmse.pop('SESGO%'))\n",
    "    df_merged_rmse.insert(2, 'SCORE%', df_merged_rmse.pop('SCORE%'))\n",
    "    df_merged_rmse.insert(3, 'RMSE', df_merged_rmse.pop('RMSE'))\n",
    "    # Restaurar el índice anterior\n",
    "    df_pronosticos_n_periodos = df_merged_rmse.set_index(['PRODUCTO', 'REGIONAL', 'MODELO'])\n",
    "        \n",
    "    return df_pronosticos_mejor_modelo, df_pronosticos_n_periodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0157032-06c6-4529-8ecd-736bc059f9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_grafica_pronostico(df, df_todos_pronosticos, df_pronosticos_mejor_modelo):\n",
    "    \n",
    "    # Crear una figura\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Lista para almacenar las trazas\n",
    "    trazas = []\n",
    "    trazas_visibilidad = []\n",
    "    \n",
    "    productos_unicos = df['PRODUCTO'].unique()\n",
    "    regionales_unicas = df['REGIONAL'].unique()\n",
    "    modelos_unicos = df_todos_pronosticos['MODELO'].unique()\n",
    "\n",
    "    # Combinación predeterminada\n",
    "    producto_default = productos_unicos[0]\n",
    "    regional_default = regionales_unicas[0]\n",
    "\n",
    "    # Generar una paleta de colores en seaborn\n",
    "    dark_colors = sns.color_palette(\"muted\", n_colors=len(modelos_unicos)).as_hex()\n",
    "    \n",
    "    # Crear un diccionario para asignar colores a cada modelo\n",
    "    color_mapping = {modelo: dark_colors[i] for i, modelo in enumerate(modelos_unicos)}\n",
    "    \n",
    "    # Crear todas las trazas (una por cada combinación de Producto, Regional y Modelo)\n",
    "    for producto in productos_unicos:\n",
    "        for regional in regionales_unicas:\n",
    "            # Filtrar datos para DEMANDA\n",
    "            df_filtrado = df[\n",
    "                (df[\"PRODUCTO\"] == producto) \n",
    "                & (df[\"REGIONAL\"] == regional)\n",
    "            ]\n",
    "    \n",
    "            # Filtrar datos para FORECAST de modelos\n",
    "            df_todos_pronosticos_filtrado = df_todos_pronosticos[\n",
    "                (df_todos_pronosticos[\"PRODUCTO\"] == producto) & \n",
    "                (df_todos_pronosticos[\"REGIONAL\"] == regional)\n",
    "            ]\n",
    "    \n",
    "            # Filtrar para el mejor modelo\n",
    "            df_pronosticos_filtrado = df_pronosticos_mejor_modelo[\n",
    "                (df_pronosticos_mejor_modelo[\"PRODUCTO\"] == producto) & \n",
    "                (df_pronosticos_mejor_modelo[\"REGIONAL\"] == regional)\n",
    "            ]\n",
    "    \n",
    "            if df_filtrado.empty or df_todos_pronosticos_filtrado.empty or df_pronosticos_filtrado.empty:\n",
    "                continue\n",
    "    \n",
    "            # Extraer el mejor modelo\n",
    "            mejor_modelo = df_pronosticos_filtrado[\"MODELO\"].values[0]\n",
    "    \n",
    "            # Agregar traza de DEMANDA\n",
    "            trazas.append(go.Scatter(\n",
    "                x=df_filtrado['Turn'], \n",
    "                y=df_filtrado[\"DEMANDA\"], \n",
    "                mode='lines',\n",
    "                name=f'Demanda {producto} - {regional}',\n",
    "                line=dict(color='navy'),\n",
    "                visible=(producto == producto_default and regional == regional_default)\n",
    "            ))\n",
    "            trazas_visibilidad.append((producto, regional, 'DEMANDA'))\n",
    "    \n",
    "            # Agregar trazas de FORECAST para todos los modelos\n",
    "            for modelo in modelos_unicos:\n",
    "                df_modelo_filtrado = df_todos_pronosticos_filtrado[\n",
    "                    df_todos_pronosticos_filtrado[\"MODELO\"] == modelo\n",
    "                ]\n",
    "                if df_modelo_filtrado.empty:\n",
    "                    continue\n",
    "    \n",
    "                line_style = dict(\n",
    "                    dash='solid' if modelo == mejor_modelo else 'dot',\n",
    "                    color=color_mapping[modelo],\n",
    "                    width=2.5 if modelo == mejor_modelo else 1.5\n",
    "                )\n",
    "    \n",
    "                trazas.append(go.Scatter(\n",
    "                    x=df_modelo_filtrado['Turn'], \n",
    "                    y=df_modelo_filtrado[\"FORECAST\"], \n",
    "                    mode='lines',\n",
    "                    name=f'{modelo}',\n",
    "                    line=line_style,\n",
    "                    visible=(producto == producto_default and regional == regional_default)\n",
    "                ))\n",
    "                trazas_visibilidad.append((producto, regional, modelo))\n",
    "    \n",
    "    # Agregar trazas a la figura\n",
    "    for traza in trazas:\n",
    "        fig.add_trace(traza)\n",
    "    \n",
    "    # Función para generar la visibilidad\n",
    "    def generar_visibilidad(producto_seleccionado, regional_seleccionado):\n",
    "        \"\"\"Genera una lista de visibilidad para las trazas.\"\"\"\n",
    "        return [\n",
    "            p == producto_seleccionado and r == regional_seleccionado\n",
    "            for p, r, _ in trazas_visibilidad\n",
    "        ]\n",
    "    \n",
    "    # Crear menús desplegables\n",
    "    buttons = []\n",
    "    for producto in productos_unicos:\n",
    "        for regional in regionales_unicas:\n",
    "            buttons.append(\n",
    "                dict(\n",
    "                    label=f\"{producto} - {regional}\",\n",
    "                    method=\"update\",\n",
    "                    args=[\n",
    "                        {\"visible\": generar_visibilidad(producto, regional)},\n",
    "                        {\"title\": f\"Producto: {producto} | Regional: {regional}\"}\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    # Actualizar el layout con los menús\n",
    "    fig.update_layout(\n",
    "        updatemenus=[\n",
    "            dict(\n",
    "                buttons=buttons,\n",
    "                direction=\"down\",\n",
    "                showactive=True,\n",
    "                x=0,\n",
    "                y=1.3,\n",
    "                xanchor=\"left\",\n",
    "                yanchor=\"top\"\n",
    "            )\n",
    "        ],\n",
    "        title=f\"Producto: {producto_default} | Regional: {regional_default}\",\n",
    "        xaxis_title=\"Turn\",\n",
    "        yaxis_title=\"Valores\",\n",
    "        legend=dict(\n",
    "        orientation=\"h\",  # Leyenda horizontal\n",
    "        x=0.5,  # Centrada horizontalmente\n",
    "        y=-0.35,  # Posición debajo de la gráfica\n",
    "        xanchor=\"center\",\n",
    "        yanchor=\"top\"\n",
    "        )\n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233531df-3a70-4728-aef0-b39f93b2af5d",
   "metadata": {},
   "source": [
    "# Holt Winters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63b85cf0-490d-4586-bc38-29b8195b938f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicar_hw(df, productos, regionales, lags, ciclos_por_año, pronostico_final=0):\n",
    "    resultados_pronostico_sku = []\n",
    "\n",
    "    for producto in productos:\n",
    "        for regional in regionales:\n",
    "            # Filtrar por producto y regional\n",
    "            df_producto_regional = df[(df['REGIONAL'] == regional) & (df['PRODUCTO'] == producto)]\n",
    "            if df_producto_regional.empty:\n",
    "                continue\n",
    "\n",
    "            serie = df_producto_regional['DEMANDA']\n",
    "            serie.index = df_producto_regional['Turn']  # Índice basado en \"Turn\"\n",
    "            \n",
    "            # Verificar valores NaN\n",
    "            if serie.isna().any():\n",
    "                print(f\"Advertencia: La serie para {producto}, {regional} contiene valores NaN. No se pronosticará.\")\n",
    "                continue\n",
    "                \n",
    "            max_rango = df['Turn'].max()\n",
    "            min_rango = -35 if pronostico_final == 0 else max_rango\n",
    "                        \n",
    "            for i in range(min_rango, max_rango+1):\n",
    "                # Dividir en entrenamiento (reseteando el índice)\n",
    "                train_index = serie.loc[:i]\n",
    "                train = train_index.reset_index(drop=True)\n",
    "    \n",
    "                # Ajustar el modelo Holt-Winters\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "                    modelo = ExponentialSmoothing(\n",
    "                        train,\n",
    "                        trend='add',\n",
    "                        seasonal='add',\n",
    "                        seasonal_periods=52/ciclos_por_año\n",
    "                    ).fit()\n",
    "                    \n",
    "                # Generar pronóstico\n",
    "                pronostico = modelo.forecast(lags)\n",
    "                \n",
    "                # Guardar resultados\n",
    "                for lag, valor in enumerate(pronostico, start=1):\n",
    "                    resultados_pronostico_sku.append({\n",
    "                        'PRODUCTO': producto,\n",
    "                        'REGIONAL': regional,\n",
    "                        'Turn': train_index.index.max() + lag,  # Índice numérico\n",
    "                        'LAG': lag,\n",
    "                        'FORECAST': valor\n",
    "                    })\n",
    "\n",
    "    # Crear DataFrame de resultados\n",
    "    df_resultados = pd.DataFrame(resultados_pronostico_sku)\n",
    "\n",
    "    if pronostico_final == 0:\n",
    "        df_forecast_hw = df_resultados.merge(df, on=['Turn', 'REGIONAL', 'PRODUCTO'], how='left').dropna()\n",
    "\n",
    "    else:\n",
    "        df_forecast_hw =  df_resultados\n",
    "    df_forecast_hw['FORECAST'] = df_forecast_hw['FORECAST'].round()    \n",
    " \n",
    "    return df_forecast_hw\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35d006f9-dffe-4e28-a576-a30243557db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicar_hw_mp(df, materias_primas, regionales, lags, ciclos_por_año, pronostico_final=0):\n",
    "    resultados_pronostico_sku = []\n",
    "\n",
    "    for materia_prima in materias_primas:\n",
    "        for regional in regionales:\n",
    "            # Filtrar por producto y regional\n",
    "            df_mp_regional = df[(df['REGIONAL'] == regional) & (df['MATERIA_PRIMA'] == materia_prima)]\n",
    "            if df_mp_regional.empty:\n",
    "                continue\n",
    "\n",
    "            serie = df_mp_regional['DEMANDA']\n",
    "            serie.index = df_mp_regional['Turn']  # Índice basado en \"Turn\"\n",
    "            \n",
    "            # Verificar valores NaN\n",
    "            if serie.isna().any():\n",
    "                print(f\"Advertencia: La serie para {materia_prima}, {regional} contiene valores NaN. No se pronosticará.\")\n",
    "                continue\n",
    "                \n",
    "            max_rango = df['Turn'].max()\n",
    "            min_rango = -35 if pronostico_final == 0 else max_rango\n",
    "                        \n",
    "            for i in range(min_rango, max_rango+1):\n",
    "                # Dividir en entrenamiento (reseteando el índice)\n",
    "                train_index = serie.loc[:i]\n",
    "                train = train_index.reset_index(drop=True)\n",
    "    \n",
    "                # Ajustar el modelo Holt-Winters\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "                    modelo = ExponentialSmoothing(\n",
    "                        train,\n",
    "                        trend='add',\n",
    "                        seasonal='add',\n",
    "                        seasonal_periods=52/ciclos_por_año\n",
    "                    ).fit()\n",
    "                    \n",
    "                # Generar pronóstico\n",
    "                pronostico = modelo.forecast(lags)\n",
    "                \n",
    "                # Guardar resultados\n",
    "                for lag, valor in enumerate(pronostico, start=1):\n",
    "                    resultados_pronostico_sku.append({\n",
    "                        'MATERIA_PRIMA': materia_prima,\n",
    "                        'REGIONAL': regional,\n",
    "                        'Turn': train_index.index.max() + lag,  # Índice numérico\n",
    "                        'LAG': lag,\n",
    "                        'FORECAST': valor\n",
    "                    })\n",
    "\n",
    "    # Crear DataFrame de resultados\n",
    "    df_resultados = pd.DataFrame(resultados_pronostico_sku)\n",
    "\n",
    "    if pronostico_final == 0:\n",
    "        df_forecast_hw = df_resultados.merge(df, on=['Turn', 'REGIONAL', 'MATERIA_PRIMA'], how='left').dropna()\n",
    "\n",
    "    else:\n",
    "        df_forecast_hw =  df_resultados\n",
    "    df_forecast_hw['FORECAST'] = df_forecast_hw['FORECAST'].round()    \n",
    " \n",
    "    return df_forecast_hw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb856e84-c87f-42fd-8af5-57961bc031d4",
   "metadata": {},
   "source": [
    "# Suavizacion Exponencial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50246692-16b3-4590-8d11-e8fa50ff844b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicar_se(df, productos, regionales, lags, pronostico_final=0):\n",
    "    resultados_pronostico_sku = []\n",
    "\n",
    "    for producto in productos:\n",
    "        for regional in regionales:\n",
    "            # Filtrar por producto y regional\n",
    "            df_producto_regional = df[(df['REGIONAL'] == regional) & (df['PRODUCTO'] == producto)]\n",
    "            if df_producto_regional.empty:\n",
    "                continue\n",
    "\n",
    "            serie = df_producto_regional['DEMANDA']\n",
    "            serie.index = df_producto_regional['Turn']  # Índice basado en \"Turn\"\n",
    "            \n",
    "            # Verificar valores NaN\n",
    "            if serie.isna().any():\n",
    "                print(f\"Advertencia: La serie para {producto}, {regional} contiene valores NaN. No se pronosticará.\")\n",
    "                continue\n",
    "                \n",
    "            max_rango = df['Turn'].max()\n",
    "            min_rango = -35 if pronostico_final == 0 else max_rango\n",
    "                        \n",
    "            for i in range(min_rango, max_rango+1):\n",
    "                # Dividir en entrenamiento (reseteando el índice)\n",
    "                train_index = serie.loc[:i]\n",
    "                train = train_index.reset_index(drop=True)\n",
    "                \n",
    "                # Ajustar el modelo Holt-Winters\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "                    modelo = SimpleExpSmoothing(\n",
    "                        train\n",
    "                    ).fit(smoothing_level=None, optimized=True)\n",
    "                                    \n",
    "                # Generar pronóstico\n",
    "                pronostico = modelo.forecast(lags)\n",
    "                \n",
    "                # Guardar resultados\n",
    "                for lag, valor in enumerate(pronostico, start=1):\n",
    "                    resultados_pronostico_sku.append({\n",
    "                        'PRODUCTO': producto,\n",
    "                        'REGIONAL': regional,\n",
    "                        'Turn': train_index.index.max() + lag,  # Índice numérico\n",
    "                        'LAG': lag,\n",
    "                        'FORECAST': valor\n",
    "                    })\n",
    "\n",
    "    # Crear DataFrame de resultados\n",
    "    df_resultados = pd.DataFrame(resultados_pronostico_sku)\n",
    "    \n",
    "    if pronostico_final == 0:\n",
    "        df_forecast_se = df_resultados.merge(df, on=['Turn', 'REGIONAL', 'PRODUCTO'], how='left').dropna()\n",
    "\n",
    "    else:\n",
    "        df_forecast_se =  df_resultados\n",
    "    df_forecast_se['FORECAST'] = df_forecast_se['FORECAST'].round() \n",
    "    return df_forecast_se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff6d1dfe-006d-4ab3-b937-44df3f35c4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicar_se_mp(df, materias_primas, regionales, lags, pronostico_final=0):\n",
    "    resultados_pronostico_sku = []\n",
    "\n",
    "    for materia_prima in materias_primas:\n",
    "        for regional in regionales:\n",
    "            # Filtrar por producto y regional\n",
    "            df_mp_regional = df[(df['REGIONAL'] == regional) & (df['MATERIA_PRIMA'] == materia_prima)]\n",
    "            if df_mp_regional.empty:\n",
    "                continue\n",
    "\n",
    "            serie = df_mp_regional['DEMANDA']\n",
    "            serie.index = df_mp_regional['Turn']  # Índice basado en \"Turn\"\n",
    "            \n",
    "            # Verificar valores NaN\n",
    "            if serie.isna().any():\n",
    "                print(f\"Advertencia: La serie para {materia_prima}, {regional} contiene valores NaN. No se pronosticará.\")\n",
    "                continue\n",
    "                \n",
    "            max_rango = df['Turn'].max()\n",
    "            min_rango = -35 if pronostico_final == 0 else max_rango\n",
    "                        \n",
    "            for i in range(min_rango, max_rango+1):\n",
    "                # Dividir en entrenamiento (reseteando el índice)\n",
    "                train_index = serie.loc[:i]\n",
    "                train = train_index.reset_index(drop=True)\n",
    "                \n",
    "                # Ajustar el modelo Holt-Winters\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "                    modelo = SimpleExpSmoothing(\n",
    "                        train\n",
    "                    ).fit(smoothing_level=None, optimized=True)\n",
    "                                    \n",
    "                # Generar pronóstico\n",
    "                pronostico = modelo.forecast(lags)\n",
    "                \n",
    "                # Guardar resultados\n",
    "                for lag, valor in enumerate(pronostico, start=1):\n",
    "                    resultados_pronostico_sku.append({\n",
    "                        'MATERIA_PRIMA': materia_prima,\n",
    "                        'REGIONAL': regional,\n",
    "                        'Turn': train_index.index.max() + lag,  # Índice numérico\n",
    "                        'LAG': lag,\n",
    "                        'FORECAST': valor\n",
    "                    })\n",
    "\n",
    "    # Crear DataFrame de resultados\n",
    "    df_resultados = pd.DataFrame(resultados_pronostico_sku)\n",
    "    \n",
    "    if pronostico_final == 0:\n",
    "        df_forecast_se = df_resultados.merge(df, on=['Turn', 'REGIONAL', 'MATERIA_PRIMA'], how='left').dropna()\n",
    "\n",
    "    else:\n",
    "        df_forecast_se =  df_resultados\n",
    "    df_forecast_se['FORECAST'] = df_forecast_se['FORECAST'].round() \n",
    "    return df_forecast_se"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9abb906-60b1-4a18-b1d2-641f7f2a35e8",
   "metadata": {},
   "source": [
    "# Promedio movil simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2dd9859f-c423-4582-8c52-cd2593f61424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicar_pms(df, productos, regionales, lags, pronostico_final=0):\n",
    "    pronostico_n = []  \n",
    "    for producto in productos:\n",
    "            for regional in regionales:\n",
    "                # Filtrar por producto y regional\n",
    "                df_producto_regional = df[(df['REGIONAL'] == regional) & (df['PRODUCTO'] == producto)]\n",
    "                if df_producto_regional.empty:\n",
    "                    continue\n",
    "    \n",
    "                serie = df_producto_regional['DEMANDA']\n",
    "                serie.index = df_producto_regional['Turn']  # Índice basado en \"Turn\"\n",
    "                \n",
    "                # Verificar valores NaN\n",
    "                if serie.isna().any():\n",
    "                    print(f\"Advertencia: La serie para {producto}, {regional} contiene valores NaN. No se pronosticará.\")\n",
    "                    continue\n",
    "\n",
    "                max_rango = df['Turn'].max()\n",
    "                min_rango = -35 if pronostico_final == 0 else max_rango\n",
    "                            \n",
    "                for i in range(min_rango, max_rango+1):\n",
    "                \n",
    "                #for i in range(-35, 0):\n",
    "                    score_n = []\n",
    "                    for n in range(3, 15):        \n",
    "                        # Dividir en entrenamiento (reseteando el índice)\n",
    "                        train = serie.loc[:i]\n",
    "                        # Ajustar el modelo PMS\n",
    "                        serie_rolling_mean_shifted = train.rolling(window=n, min_periods=1).mean().shift(1)\n",
    "                        # Crear la serie 'error' restando las dos series\n",
    "                        error = (train - serie_rolling_mean_shifted).dropna()                    \n",
    "                        # Crear la serie 'error_abs' con los valores absolutos\n",
    "                        error_abs = error.abs()                    \n",
    "                        # Calcular la variable mae_porc                                       \n",
    "                        mae_porc = error_abs.sum() / train.loc[error.index].sum()                    \n",
    "                        # Calcular la variable sesgo\n",
    "                        sesgo = error.sum() / train.loc[error.index].sum()                    \n",
    "                        # Calcular Score\n",
    "                        score = mae_porc + abs(sesgo)\n",
    "                        #print('n:',n,'Score:',score)\n",
    "                        score_n.append({\n",
    "                            'n':n,\n",
    "                            'score':score\n",
    "                            })\n",
    "                    #print('Turn:', i)\n",
    "                    #print(score_n)\n",
    "                    # Encontrar el diccionario con el menor score\n",
    "                    mejor_score = min(score_n, key=lambda x: x['score'])\n",
    "                    # Obtener el valor de 'n' con el menor score\n",
    "                    mejor_n = mejor_score['n']\n",
    "                    # Identificar menor score\n",
    "                    score_minimo = mejor_score['score']\n",
    "                    # Generar pronostico con mejor_n\n",
    "                    pronostico = [train.rolling(window=mejor_n, min_periods=1).mean().iloc[-1]]*lags\n",
    "                    \n",
    "                    for lag, valor in enumerate(pronostico, start=1):\n",
    "                        pronostico_n.append({\n",
    "                            'Turn': train.index.max() + lag,\n",
    "                            'PRODUCTO': producto,\n",
    "                            'REGIONAL': regional,\n",
    "                            'LAG': lag,\n",
    "                            'FORECAST': valor,\n",
    "                            'MEJOR_n': mejor_n\n",
    "                        })\n",
    "    df_resultados = pd.DataFrame(pronostico_n)\n",
    "    if pronostico_final == 0:\n",
    "        df_forecast_pms = df_resultados.merge(df, on=['Turn', 'REGIONAL', 'PRODUCTO'], how='left').dropna()\n",
    "\n",
    "    else:\n",
    "        df_forecast_pms =  df_resultados\n",
    "    df_forecast_pms['FORECAST'] = df_forecast_pms['FORECAST'].round() \n",
    "    return df_forecast_pms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3fdc45bd-ce92-455f-b38d-e8ada48f875f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicar_pms_mp(df, materias_primas, regionales, lags, pronostico_final=0):\n",
    "    pronostico_n = []  \n",
    "    for producto in productos:\n",
    "            for materia_prima in materias_primas:\n",
    "                # Filtrar por producto y regional\n",
    "                df_mp_regional = df[(df['REGIONAL'] == regional) & (df['MATERIA_PRIMA'] == materia_prima)]\n",
    "                if df_mp_regional.empty:\n",
    "                    continue\n",
    "    \n",
    "                serie = df_mp_regional['DEMANDA']\n",
    "                serie.index = df_mp_regional['Turn']  # Índice basado en \"Turn\"\n",
    "                \n",
    "                # Verificar valores NaN\n",
    "                if serie.isna().any():\n",
    "                    print(f\"Advertencia: La serie para {materia_prima}, {regional} contiene valores NaN. No se pronosticará.\")\n",
    "                    continue\n",
    "\n",
    "                max_rango = df['Turn'].max()\n",
    "                min_rango = -35 if pronostico_final == 0 else max_rango\n",
    "                            \n",
    "                for i in range(min_rango, max_rango+1):\n",
    "                \n",
    "                #for i in range(-35, 0):\n",
    "                    score_n = []\n",
    "                    for n in range(3, 15):        \n",
    "                        # Dividir en entrenamiento (reseteando el índice)\n",
    "                        train = serie.loc[:i]\n",
    "                        # Ajustar el modelo PMS\n",
    "                        serie_rolling_mean_shifted = train.rolling(window=n, min_periods=1).mean().shift(1)\n",
    "                        # Crear la serie 'error' restando las dos series\n",
    "                        error = (train - serie_rolling_mean_shifted).dropna()                    \n",
    "                        # Crear la serie 'error_abs' con los valores absolutos\n",
    "                        error_abs = error.abs()                    \n",
    "                        # Calcular la variable mae_porc                                       \n",
    "                        mae_porc = error_abs.sum() / train.loc[error.index].sum()                    \n",
    "                        # Calcular la variable sesgo\n",
    "                        sesgo = error.sum() / train.loc[error.index].sum()                    \n",
    "                        # Calcular Score\n",
    "                        score = mae_porc + abs(sesgo)\n",
    "                        #print('n:',n,'Score:',score)\n",
    "                        score_n.append({\n",
    "                            'n':n,\n",
    "                            'score':score\n",
    "                            })\n",
    "                    #print('Turn:', i)\n",
    "                    #print(score_n)\n",
    "                    # Encontrar el diccionario con el menor score\n",
    "                    mejor_score = min(score_n, key=lambda x: x['score'])\n",
    "                    # Obtener el valor de 'n' con el menor score\n",
    "                    mejor_n = mejor_score['n']\n",
    "                    # Identificar menor score\n",
    "                    score_minimo = mejor_score['score']\n",
    "                    # Generar pronostico con mejor_n\n",
    "                    pronostico = [train.rolling(window=mejor_n, min_periods=1).mean().iloc[-1]]*lags\n",
    "                    \n",
    "                    for lag, valor in enumerate(pronostico, start=1):\n",
    "                        pronostico_n.append({\n",
    "                            'Turn': train.index.max() + lag,\n",
    "                            'MATERIA_PRIMA': materia_prima,\n",
    "                            'REGIONAL': regional,\n",
    "                            'LAG': lag,\n",
    "                            'FORECAST': valor,\n",
    "                            'MEJOR_n': mejor_n\n",
    "                        })\n",
    "    df_resultados = pd.DataFrame(pronostico_n)\n",
    "    if pronostico_final == 0:\n",
    "        df_forecast_pms = df_resultados.merge(df, on=['Turn', 'REGIONAL', 'MATERIA_PRIMA'], how='left').dropna()\n",
    "\n",
    "    else:\n",
    "        df_forecast_pms =  df_resultados\n",
    "    df_forecast_pms['FORECAST'] = df_forecast_pms['FORECAST'].round() \n",
    "    return df_forecast_pms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
